{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0a5a0",
   "metadata": {},
   "source": [
    "# Offline image preprocessing\n",
    "I conducted experiments with different preprocessing approaches. To make the computations faster, I applied some of the preprocessing methods offline, before training and stored the preprocessed images in new dataset subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "090b51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from image_preprocessing import *\n",
    "from utils import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d15556",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ea06cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MURA_DIR= '../datasets/original/' # Directory with original MURA dataset\n",
    "CLAHE_2_DIR= '../datasets/clahe_2/' # Directory for CLAHE preprocessed dataset with clipLimit=2\n",
    "CLAHE_10_DIR= '../datasets/clahe_10/' # Directory for CLAHE preprocessed dataset with clipLimit=10\n",
    "DATASET_PATH= '../datasets/tvt_detailed_paths.csv' # Path to csv file with dataset information (train-valid-test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90ccee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset dataframe, as we will preprocess all images\n",
    "df = get_dataframe('ALL', 'ALL', DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5dd339",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cfe39fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_dir_structure(src, dest):\n",
    "    \"\"\"\n",
    "    Clones full directory structure inside source path to destination path, excluding files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src: str\n",
    "        Directory structure source\n",
    "    dest: str\n",
    "        Directory structure destination\n",
    "\n",
    "    \"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(src):\n",
    "        folder = os.path.join(dest, dirpath[len(src):])\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "            \n",
    "def create_clahe_dataset(df, clip, src, dest):\n",
    "    \"\"\"\n",
    "    Applies CLAHE method to all images provided in dataframe and saves them. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.Dataframe\n",
    "        Dataframe with one image per row, must have column \"filepath\" containing image filepath\n",
    "    clip: float\n",
    "        Clip limit used in the CLAHE method from opencv library\n",
    "    src: str\n",
    "        Source directory prefix for filepaths from dataframe, as they are not absolute\n",
    "    dest: str\n",
    "        Destination directory prefix for filepaths from dataframe, as they are not absolute\n",
    "    \"\"\"\n",
    "    for filepath in df['filepath']:\n",
    "        img = cv2.imread(src + filepath)\n",
    "        clahe_img = clahe(img, clip=clip, tile=(8, 8))\n",
    "        cv2.imwrite(dest + filepath, clahe_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e8963",
   "metadata": {},
   "source": [
    "# Create CLAHE dataset\n",
    "## clipLimit=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "487b8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40005 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x7f2ab2d5a100>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone original MURA dataset structure, excluding files\n",
    "clone_dir_structure(MURA_DIR, CLAHE_2_DIR)\n",
    "\n",
    "# Create clahe preprocessed dataset with clipLimit=2\n",
    "create_clahe_dataset(df, 2, MURA_DIR, CLAHE_2_DIR)\n",
    "\n",
    "# Verify that all images were succesfully transfered (there should be no non-existing paths in the dataframe)\n",
    "gen = ImageDataGenerator()\n",
    "gen.flow_from_dataframe(dataframe=df,\n",
    "                        directory=CLAHE_2_DIR,\n",
    "                        x_col='filepath',\n",
    "                        y_col='label',\n",
    "                        class_mode='binary',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d4dcc",
   "metadata": {},
   "source": [
    "## clipLimit=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08f0a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40005 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x7f2ab2d5b310>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone original MURA dataset structure, excluding files\n",
    "# clone_dir_structure(MURA_DIR, CLAHE_10_DIR)\n",
    "\n",
    "# Create clahe preprocessed dataset with clipLimit=10\n",
    "create_clahe_dataset(df, 10, MURA_DIR, CLAHE_10_DIR)\n",
    "\n",
    "# Verify that all images were succesfully transfered (there should be no non-existing paths in the dataframe)\n",
    "gen = ImageDataGenerator()\n",
    "gen.flow_from_dataframe(dataframe=df,\n",
    "                        directory=CLAHE_10_DIR,\n",
    "                        x_col='filepath',\n",
    "                        y_col='label',\n",
    "                        class_mode='binary',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
