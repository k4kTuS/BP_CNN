{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter_optimization_DenseNet169.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter optimization - DenseNet169\n",
        "* This notebook was used to optimize hyperparameters for DenseNet169 architecture, using Keras tuner library\n",
        "* It already contains the results from the hyperband search"
      ],
      "metadata": {
        "id": "8rd7zjOcXLTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JjJVSpXfyWg"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Google Colab does not have tensorflow_addons installed by default\n",
        "!pip install tensorflow-addons\n",
        "from tensorflow_addons.metrics import CohenKappa\n",
        "\n",
        "# Install keras-tuner\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FILEPATHS"
      ],
      "metadata": {
        "id": "vte6fR-hhY4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_DIR = '/content/drive/MyDrive/MURA/' # Directory in my personal Google Drive with all source files and datasets\n",
        "MURA_DIR = '/content/original/' # Directory with original MURA dataset\n",
        "CLAHE_2_DIR = '/content/clahe_2/' # Directory for CLAHE preprocessed dataset with clipLimit=2\n",
        "CLAHE_10_DIR = '/content/clahe_10/' # Directory for CLAHE preprocessed dataset with clipLimit=10\n",
        "CROPPED_DIR = '/content/cropped/' # Directory for custom cropping preprocessed dataset\n",
        "DATAFRAME_PATH = DRIVE_DIR + '/tvt_detailed_paths.csv' # Path to csv file with dataset information (train-valid-test split)"
      ],
      "metadata": {
        "id": "chR2OBqAYd4V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab specific section"
      ],
      "metadata": {
        "id": "djVz8HVw7oEY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82nFEA2TjZ3q"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afiSbqU-ajuW",
        "outputId": "a30337bf-b2fc-402f-d6f6-1a8cd6afe84a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google colab functions\n",
        "\n",
        "Next cell containts function definitions, that are needed or useful when running notebook in Google Colab, such as copying dataset from Google Drive, checking GPU utilization, copying other files from Google Drive."
      ],
      "metadata": {
        "id": "eMOttX7zz_tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is from Google Colab guide notebooks: https://colab.research.google.com/notebooks/pro.ipynb\n",
        "def check_gpu():\n",
        "  \"\"\"\n",
        "  Prints information about available GPU or message saying there isn't one\n",
        "  \"\"\"\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "\n",
        "\n",
        "def init_file_struct():\n",
        "  \"\"\"\n",
        "  Prep file structure in Google Colab and copies neccessary files from Google Drive\n",
        "  \"\"\"\n",
        "  !cp \"{DRIVE_DIR}src/utils.py\" .\n",
        "  !cp \"{DRIVE_DIR}src/image_preprocessing.py\" .\n",
        "\n",
        "\n",
        "def copy_dataset(filename):\n",
        "  \"\"\"\n",
        "  Copies and unzips dataset from Google Drive and deletes the zipped file\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename : str\n",
        "    Dataset filename, without its path, the path will be added from constants\n",
        "  \"\"\"\n",
        "  !cp {DRIVE_DIR}{filename} /content/\n",
        "\n",
        "  !unzip -q /content/{filename}\n",
        "\n",
        "  !rm /content/{filename}"
      ],
      "metadata": {
        "id": "JdCdOOo5z5kU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import python files after copying them from Google Colab"
      ],
      "metadata": {
        "id": "3iQ5LRSN5bKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_file_struct()\n",
        "from utils import *\n",
        "from image_preprocessing import *"
      ],
      "metadata": {
        "id": "lA5yYz1FsD4f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy desired dataset to be used"
      ],
      "metadata": {
        "id": "foQIO96o5k_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_dataset('original.zip')\n",
        "# copy_dataset('clahe_2.zip')\n",
        "# copy_dataset('clahe_10.zip')\n",
        "# copy_dataset('cropped.zip')"
      ],
      "metadata": {
        "id": "T02MSGga5kNU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "oVPVFQRBiLtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATAFRAME\n",
        "BODY_PART = 'SHOULDER' # Which body part to use, can be \"ALL\" for full dataset\n",
        "# IMAGE AUGMENTATION\n",
        "ROTATION_R = 20 # Rotation range\n",
        "W_SHIFT_R = 0.05 # Width shift range\n",
        "H_SHIFT_R = 0.05 # Height shift range\n",
        "BRIGHTNESS_R = (0.9, 1.1) # Brightness range\n",
        "ZOOM_R = 0.1 # Zoom range\n",
        "H_FLIP = True # Flip the image horizontally\n",
        "PRE_FUNC = rescale # Preprocessing function\n",
        "# DATAFRAME FLOW\n",
        "IMAGE_SIZE = (224, 224) # Resize all images to this size\n",
        "# MODEL\n",
        "BASE_NAME = 'DenseNet169' # Name corresponding to one of the architectures from Keras functional API\n",
        "WEIGHTS = 'imagenet' # ImageNet pre-trained weights or a path to stored model weights\n",
        "INPUT_SHAPE = (224, 224, 3) # Model input shape\n",
        "MODEL_NAME = BASE_NAME + '_tuning' # Name used for storing model weights during and after training\n",
        "# TUNING\n",
        "BATCH_SIZE = [8, 16, 32] # Batch size options\n",
        "POOLING = ['avg', 'max'] # Pooling options\n",
        "LEARNING_RATE = [0.001, 0.0005, 0.00025, 0.0001, 0.00005] # Adam learning rate options\n",
        "MAX_EPOCHS = 7 # Maximum epochs for one trial run\n",
        "EPOCHS = 80 # Maximum number of epochs for whole tuning"
      ],
      "metadata": {
        "id": "ZPBBFX6IiKaw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create datagens and flows"
      ],
      "metadata": {
        "id": "dopwQuPxkZV_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggqBTn15ab-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1870638f-107d-40ad-bcfc-4acc32cd65da"
      },
      "source": [
        "# Create dataframes from train valid split\n",
        "train_df = get_dataframe(body_part=BODY_PART, split='train', path=DATAFRAME_PATH)\n",
        "valid_df = get_dataframe(body_part=BODY_PART, split='valid', path=DATAFRAME_PATH)\n",
        "\n",
        "# Create ImageDataGenerators, train_gen uses specified online augmentation, valid_gen only preprocesses images\n",
        "train_gen, valid_gen = create_generators(rotation_r=ROTATION_R,\n",
        "                                         w_shift_r=W_SHIFT_R,\n",
        "                                         h_shift_r=H_SHIFT_R,\n",
        "                                         brightness_r=BRIGHTNESS_R,\n",
        "                                         zoom_r=ZOOM_R,\n",
        "                                         h_flip=H_FLIP,\n",
        "                                         pre_func=PRE_FUNC)\n",
        "\n",
        "# Create dataframe flows, using batch size as hyperparameter\n",
        "train_flow, valid_flow = create_dataframe_flows(train_gen=train_gen,\n",
        "                                                valid_gen=valid_gen,\n",
        "                                                train_df=train_df,\n",
        "                                                valid_df=valid_df,\n",
        "                                                directory=MURA_DIR,\n",
        "                                                img_size=IMAGE_SIZE)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8257 validated image filenames belonging to 2 classes.\n",
            "Found 563 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for building the model using tuned hyperparameters\n",
        "def build_hyperparam(hp):\n",
        "  hp_pool = hp.Choice('pool', POOLING) # Pooling after last conv layer\n",
        "  hp_lr = hp.Choice('lr', LEARNING_RATE) # Adam initial learning rate\n",
        "  hp_batch_size = hp.Choice('batch_size', BATCH_SIZE) # Batch size\n",
        "\n",
        "  # Set batch size\n",
        "  train_flow.batch_size = hp_batch_size\n",
        "  valid_flow.batch_size = hp_batch_size\n",
        "\n",
        "  # Call function for building model from utils.py\n",
        "  model = build_model(base_name=BASE_NAME,\n",
        "                      weights=WEIGHTS,\n",
        "                      shape=INPUT_SHAPE,\n",
        "                      name=MODEL_NAME,\n",
        "                      pooling=hp_pool,\n",
        "                      optimizer=Adam(learning_rate=hp_lr))\n",
        "  return model"
      ],
      "metadata": {
        "id": "Rnli6_XNklhu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tuner using Hyperband search\n",
        "tuner = kt.Hyperband(\n",
        "    hypermodel=build_hyperparam,\n",
        "    objective=kt.Objective('val_kappa', 'max'),\n",
        "    max_epochs=MAX_EPOCHS,\n",
        "    overwrite=True,\n",
        "    directory=DRIVE_DIR + \"tuning\",\n",
        "    project_name=\"densenet169_hp\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6ieHuttoAeh",
        "outputId": "0a90eec4-61b0-4749-9410-518b17618945"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n",
            "51888128/51877672 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_kappa',\n",
        "                           mode='max',\n",
        "                           min_delta=0,\n",
        "                           patience=5,\n",
        "                           restore_best_weights=True)\n",
        "\n",
        "tuner.search(x=train_flow, epochs=EPOCHS, validation_data=valid_flow, class_weight=get_class_weights(train_df), verbose=1, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0694KZ9JqRPB",
        "outputId": "b583cedd-d688-48d5-ae5e-131e5452960e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 22m 01s]\n",
            "val_kappa: 0.5517345666885376\n",
            "\n",
            "Best val_kappa So Far: 0.5986765623092651\n",
            "Total elapsed time: 02h 20m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best model parameters\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "# Get search space and best parameters\n",
        "hp_config = best_hp.get_config().get('space')\n",
        "hp_params = best_hp.get_config().get('values')\n",
        "\n",
        "# Print summary\n",
        "print('------------------------------\\nHyperparameter tuning summary:\\n------------------------------')\n",
        "print('Model:', BASE_NAME)\n",
        "print('Searched parameters:\\n------------------------------')\n",
        "for parameter in hp_config:\n",
        "  print(parameter['config']['name'], ':', parameter['config']['values'])\n",
        "print('------------------------------')\n",
        "print('Best parameter config:\\n------------------------------')\n",
        "for key in hp_params.keys():\n",
        "  print(key, ':', hp_params[key])\n",
        "print('------------------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb1xMuhbM4yj",
        "outputId": "5028e86b-c79e-475e-92f5-483a2944b811"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Hyperparameter tuning summary:\n",
            "------------------------------\n",
            "Model: DenseNet169\n",
            "Searched parameters:\n",
            "------------------------------\n",
            "pool : ['avg', 'max']\n",
            "lr : [0.001, 0.0005, 0.00025, 0.0001, 5e-05]\n",
            "batch_size : [8, 16, 32]\n",
            "------------------------------\n",
            "Best parameter config:\n",
            "------------------------------\n",
            "pool : avg\n",
            "lr : 0.0001\n",
            "batch_size : 16\n",
            "tuner/epochs : 7\n",
            "tuner/initial_epoch : 3\n",
            "tuner/bracket : 1\n",
            "tuner/round : 1\n",
            "tuner/trial_id : 0001\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional - print full summary\n",
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEGZHJjLxPXE",
        "outputId": "bcb262dc-49c4-450b-afd5-d285563330cf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in /content/drive/MyDrive/MURA/tuning/densenet169_hp\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f331d168550>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.0001\n",
            "batch_size: 16\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0001\n",
            "Score: 0.5986765623092651\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: max\n",
            "lr: 0.0001\n",
            "batch_size: 32\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.5517345666885376\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.0001\n",
            "batch_size: 16\n",
            "tuner/epochs: 3\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.5511786937713623\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.0001\n",
            "batch_size: 8\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.5373811721801758\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: max\n",
            "lr: 5e-05\n",
            "batch_size: 32\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 3\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0002\n",
            "Score: 0.49190616607666016\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: max\n",
            "lr: 5e-05\n",
            "batch_size: 32\n",
            "tuner/epochs: 3\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.33928990364074707\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: max\n",
            "lr: 0.0005\n",
            "batch_size: 8\n",
            "tuner/epochs: 3\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.30699336528778076\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.0005\n",
            "batch_size: 8\n",
            "tuner/epochs: 3\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.24231863021850586\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.001\n",
            "batch_size: 32\n",
            "tuner/epochs: 7\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.1451714038848877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "pool: avg\n",
            "lr: 0.001\n",
            "batch_size: 8\n",
            "tuner/epochs: 3\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.080233633518219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NrDivkBNNuEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}